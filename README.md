# JDsAnalysis
  
The task is to use Pyspark to solve a big data problem. In this project, the Databricks for Community Edition is used. Amazon Web Services (AWS) is chosen as the cloud provider. A notebook is created within the Databricks workplace with PySpark using a cluster (12.2 LTS (Scala 2.12, Spark 3.3.2)).
  
- Work out the frequencies with which distinct skills are mentioned in job descriptions, and present the top 10 skills, alongside the frequency of each across the entire dataset; check how the distribution of the frequencies with which distinct skills are mentioned in JDs changes if lowercase all the skills  
<img width="453" alt="image" src="https://github.com/nighttttrain/JDsAnalysis/assets/127153246/98e20de8-638f-4475-b1d4-47b2fde38376">

<img width="450" alt="image" src="https://github.com/nighttttrain/JDsAnalysis/assets/127153246/ed5768d1-b0d9-4172-8523-b7a006882c24">  
  
- Find the 5 most frequent numbers of skills in JDs across the dataset
<img width="453" alt="image" src="https://github.com/nighttttrain/JDsAnalysis/assets/127153246/6cab6171-1202-47e9-af19-7937ad29baa3">
  
- Join the skills from JDs in the O*NET dataset to gain more insight

<img width="453" alt="image" src="https://github.com/nighttttrain/JDsAnalysis/assets/127153246/98ca9449-a962-42d8-8be9-955e2e381d15">
<img width="453" alt="image" src="https://github.com/nighttttrain/JDsAnalysis/assets/127153246/60247a95-a928-4bb8-a2a9-e150aef382ea">
  
- Find the 10 most frequent “Commodity Title” across all the job descriptions  
<img width="453" alt="image" src="https://github.com/nighttttrain/JDsAnalysis/assets/127153246/2be895d5-72a1-47bd-bb24-dae1698a21d7">






